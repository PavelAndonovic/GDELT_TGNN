{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7dd8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "sys.path.append('../../model/geometric_temporal/')\n",
    "sys.path.append('../../dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1682c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recurrent import LSTMGCNModel\n",
    "from gdelt_dataset import GDELTDatasetLoader\n",
    "from torch_geometric_temporal.signal import DynamicGraphTemporalSignal\n",
    "seed = torch.random.manual_seed(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "820a471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abc3e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GDELTDatasetLoader('../../data/dataset/gdelt_data_2.pkl', 1000)\n",
    "dataset = loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a395473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMGCNModel(7, 5, 1, 3)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0da5e07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 2.6046e-01,  2.3336e-01, -4.0358e-01, -5.4300e-02, -3.7106e-01],\n",
       "         [ 6.7656e-01, -6.8942e-01, -3.4608e-01,  3.3522e-02,  4.6748e-01],\n",
       "         [ 5.1704e-01, -4.8018e-01, -2.1699e-01,  2.9059e-01,  1.8975e-01],\n",
       "         [ 4.2044e-01,  3.2515e-01, -6.5118e-01, -2.1279e-01,  7.0990e-03],\n",
       "         [-1.3022e-01,  3.5641e-01, -4.8853e-01,  4.0386e-01,  1.7466e-01],\n",
       "         [ 3.2112e-01,  1.6990e-01, -6.6140e-01,  3.8928e-04,  1.2960e-01],\n",
       "         [ 5.0093e-01, -5.8758e-01, -1.2861e-01, -3.2961e-01, -1.2037e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0., 0., 0., 0., 0.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.3509,  0.2890,  0.1128, -0.0027,  0.4863],\n",
       "         [ 0.3039,  0.4165,  0.5185, -0.2399,  0.5408],\n",
       "         [ 0.0609, -0.2603,  0.5564, -0.5055,  0.0474],\n",
       "         [ 0.1932,  0.2182,  0.2020,  0.1924,  0.5180],\n",
       "         [ 0.5329, -0.0621, -0.4194,  0.4961,  0.3963],\n",
       "         [ 0.1215, -0.5707,  0.2380,  0.2683, -0.6108],\n",
       "         [-0.0943,  0.4907, -0.0861, -0.3116,  0.2079]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0., 0., 0., 0., 0.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.6079,  0.6533,  0.4384,  0.6810,  0.2385],\n",
       "         [-0.4995, -0.0682,  0.3538,  0.6759, -0.5803],\n",
       "         [-0.2812,  0.2350,  0.5295,  0.5131,  0.6960],\n",
       "         [-0.4470,  0.1079,  0.1642, -0.3217,  0.4793],\n",
       "         [-0.4100, -0.6020, -0.3824,  0.6974,  0.0326],\n",
       "         [ 0.3122,  0.2636,  0.3567, -0.0090, -0.4669],\n",
       "         [-0.2480, -0.6342,  0.1833, -0.6907,  0.2555]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0., 0., 0., 0., 0.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.3898, -0.3940,  0.2164,  0.5458,  0.5769],\n",
       "         [-0.4886,  0.6157,  0.6709,  0.0363, -0.2292],\n",
       "         [-0.2516, -0.6517,  0.3908, -0.4285,  0.3844],\n",
       "         [-0.4284,  0.3206, -0.3717, -0.6548,  0.6942],\n",
       "         [-0.3168, -0.0216,  0.2266,  0.2937,  0.3018],\n",
       "         [-0.1767, -0.4970,  0.2467, -0.4213, -0.1672],\n",
       "         [ 0.6941,  0.1004, -0.1309, -0.3098,  0.3285]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0., 0., 0., 0., 0.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.3869,  0.6623,  0.4005,  0.4867, -0.4432],\n",
       "         [-0.2484, -0.7172, -0.6468, -0.2598,  0.1134],\n",
       "         [-0.1154, -0.2717, -0.5530,  0.5901,  0.1853],\n",
       "         [-0.1442, -0.1804, -0.2970,  0.7232, -0.5081],\n",
       "         [ 0.3936, -0.3583, -0.4268, -0.7403,  0.5907]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2927,  0.1240, -0.6480, -0.5797,  0.3901],\n",
       "         [-0.1369, -0.5966, -0.5573, -0.5242, -0.1267],\n",
       "         [-0.4173,  0.5362, -0.6538,  0.3297,  0.6753],\n",
       "         [ 0.4757,  0.0402, -0.0632, -0.6161, -0.3051],\n",
       "         [ 0.6520,  0.1094, -0.0750, -0.4270,  0.2666]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.6398,  0.6946,  0.7642, -0.5553, -0.5113],\n",
       "         [-0.7664, -0.3208,  0.2273, -0.4053, -0.6658],\n",
       "         [ 0.1522,  0.2427, -0.0662, -0.6138, -0.5392],\n",
       "         [ 0.0225,  0.1051,  0.1821,  0.3483, -0.2131],\n",
       "         [-0.2651, -0.5933,  0.4874,  0.0527,  0.3188]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.5849,  0.5682,  0.4200, -0.6527,  0.3338],\n",
       "         [-0.4893,  0.5894,  0.1374,  0.1297, -0.1111],\n",
       "         [ 0.6528,  0.0814, -0.4143, -0.5730,  0.5058],\n",
       "         [-0.5485,  0.0146,  0.4364, -0.0696,  0.3223],\n",
       "         [-0.5947,  0.1901, -0.1552, -0.1022, -0.0618]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1696,  0.3723, -0.0881, -0.2760, -0.1052],\n",
       "         [ 0.2490,  0.2781,  0.0071,  0.0480, -0.1875],\n",
       "         [ 0.4150, -0.2699,  0.1071, -0.3651, -0.3495]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1461, -0.1081,  0.0421], requires_grad=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5d21a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 120.0234603881836, Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 1/10 [00:05<00:46,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm.W_i tensor([[nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan]])\n",
      "lstm.W_i tensor([[ 2.6046e-01,  2.3336e-01, -4.0358e-01, -5.4300e-02, -3.7106e-01],\n",
      "        [ 6.7656e-01, -6.8942e-01, -3.4608e-01,  3.3522e-02,  4.6748e-01],\n",
      "        [ 5.1704e-01, -4.8018e-01, -2.1699e-01,  2.9059e-01,  1.8975e-01],\n",
      "        [ 4.2044e-01,  3.2515e-01, -6.5118e-01, -2.1279e-01,  7.0990e-03],\n",
      "        [-1.3022e-01,  3.5641e-01, -4.8853e-01,  4.0386e-01,  1.7466e-01],\n",
      "        [ 3.2112e-01,  1.6990e-01, -6.6140e-01,  3.8928e-04,  1.2960e-01],\n",
      "        [ 5.0093e-01, -5.8758e-01, -1.2861e-01, -3.2961e-01, -1.2037e-01]])\n",
      "lstm.b_i tensor([[nan, nan, nan, nan, nan]])\n",
      "lstm.b_i tensor([[0., 0., 0., 0., 0.]])\n",
      "lstm.W_f tensor([[nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan]])\n",
      "lstm.W_f tensor([[ 0.3509,  0.2890,  0.1128, -0.0027,  0.4863],\n",
      "        [ 0.3039,  0.4165,  0.5185, -0.2399,  0.5408],\n",
      "        [ 0.0609, -0.2603,  0.5564, -0.5055,  0.0474],\n",
      "        [ 0.1932,  0.2182,  0.2020,  0.1924,  0.5180],\n",
      "        [ 0.5329, -0.0621, -0.4194,  0.4961,  0.3963],\n",
      "        [ 0.1215, -0.5707,  0.2380,  0.2683, -0.6108],\n",
      "        [-0.0943,  0.4907, -0.0861, -0.3116,  0.2079]])\n",
      "lstm.b_f tensor([[nan, nan, nan, nan, nan]])\n",
      "lstm.b_f tensor([[0., 0., 0., 0., 0.]])\n",
      "lstm.W_c tensor([[nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan]])\n",
      "lstm.W_c tensor([[ 0.6079,  0.6533,  0.4384,  0.6810,  0.2385],\n",
      "        [-0.4995, -0.0682,  0.3538,  0.6759, -0.5803],\n",
      "        [-0.2812,  0.2350,  0.5295,  0.5131,  0.6960],\n",
      "        [-0.4470,  0.1079,  0.1642, -0.3217,  0.4793],\n",
      "        [-0.4100, -0.6020, -0.3824,  0.6974,  0.0326],\n",
      "        [ 0.3122,  0.2636,  0.3567, -0.0090, -0.4669],\n",
      "        [-0.2480, -0.6342,  0.1833, -0.6907,  0.2555]])\n",
      "lstm.b_c tensor([[nan, nan, nan, nan, nan]])\n",
      "lstm.b_c tensor([[0., 0., 0., 0., 0.]])\n",
      "lstm.W_o tensor([[nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan]])\n",
      "lstm.W_o tensor([[-0.3898, -0.3940,  0.2164,  0.5458,  0.5769],\n",
      "        [-0.4886,  0.6157,  0.6709,  0.0363, -0.2292],\n",
      "        [-0.2516, -0.6517,  0.3908, -0.4285,  0.3844],\n",
      "        [-0.4284,  0.3206, -0.3717, -0.6548,  0.6942],\n",
      "        [-0.3168, -0.0216,  0.2266,  0.2937,  0.3018],\n",
      "        [-0.1767, -0.4970,  0.2467, -0.4213, -0.1672],\n",
      "        [ 0.6941,  0.1004, -0.1309, -0.3098,  0.3285]])\n",
      "lstm.b_o tensor([[nan, nan, nan, nan, nan]])\n",
      "lstm.b_o tensor([[0., 0., 0., 0., 0.]])\n",
      "lstm.conv_i.bias tensor([nan, nan, nan, nan, nan])\n",
      "lstm.conv_i.bias tensor([0., 0., 0., 0., 0.])\n",
      "lstm.conv_i.lins.0.weight tensor([[nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan]])\n",
      "lstm.conv_i.lins.0.weight tensor([[-0.3869,  0.6623,  0.4005,  0.4867, -0.4432],\n",
      "        [-0.2484, -0.7172, -0.6468, -0.2598,  0.1134],\n",
      "        [-0.1154, -0.2717, -0.5530,  0.5901,  0.1853],\n",
      "        [-0.1442, -0.1804, -0.2970,  0.7232, -0.5081],\n",
      "        [ 0.3936, -0.3583, -0.4268, -0.7403,  0.5907]])\n",
      "lstm.conv_f.bias tensor([nan, nan, nan, nan, nan])\n",
      "lstm.conv_f.bias tensor([0., 0., 0., 0., 0.])\n",
      "lstm.conv_f.lins.0.weight tensor([[nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan]])\n",
      "lstm.conv_f.lins.0.weight tensor([[ 0.2927,  0.1240, -0.6480, -0.5797,  0.3901],\n",
      "        [-0.1369, -0.5966, -0.5573, -0.5242, -0.1267],\n",
      "        [-0.4173,  0.5362, -0.6538,  0.3297,  0.6753],\n",
      "        [ 0.4757,  0.0402, -0.0632, -0.6161, -0.3051],\n",
      "        [ 0.6520,  0.1094, -0.0750, -0.4270,  0.2666]])\n",
      "lstm.conv_c.bias tensor([nan, nan, nan, nan, nan])\n",
      "lstm.conv_c.bias tensor([0., 0., 0., 0., 0.])\n",
      "lstm.conv_c.lins.0.weight tensor([[nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan]])\n",
      "lstm.conv_c.lins.0.weight tensor([[-0.6398,  0.6946,  0.7642, -0.5553, -0.5113],\n",
      "        [-0.7664, -0.3208,  0.2273, -0.4053, -0.6658],\n",
      "        [ 0.1522,  0.2427, -0.0662, -0.6138, -0.5392],\n",
      "        [ 0.0225,  0.1051,  0.1821,  0.3483, -0.2131],\n",
      "        [-0.2651, -0.5933,  0.4874,  0.0527,  0.3188]])\n",
      "lstm.conv_o.bias tensor([nan, nan, nan, nan, nan])\n",
      "lstm.conv_o.bias tensor([0., 0., 0., 0., 0.])\n",
      "lstm.conv_o.lins.0.weight tensor([[nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan]])\n",
      "lstm.conv_o.lins.0.weight tensor([[-0.5849,  0.5682,  0.4200, -0.6527,  0.3338],\n",
      "        [-0.4893,  0.5894,  0.1374,  0.1297, -0.1111],\n",
      "        [ 0.6528,  0.0814, -0.4143, -0.5730,  0.5058],\n",
      "        [-0.5485,  0.0146,  0.4364, -0.0696,  0.3223],\n",
      "        [-0.5947,  0.1901, -0.1552, -0.1022, -0.0618]])\n",
      "linear.weight tensor([[nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan]])\n",
      "linear.weight tensor([[ 0.1696,  0.3723, -0.0881, -0.2760, -0.1052],\n",
      "        [ 0.2490,  0.2781,  0.0071,  0.0480, -0.1875],\n",
      "        [ 0.4150, -0.2699,  0.1071, -0.3651, -0.3495]])\n",
      "linear.bias tensor([nan, nan, nan])\n",
      "linear.bias tensor([ 0.1461, -0.1081,  0.0421])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 1/10 [00:08<01:19,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 121.29145050048828, Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17540\\1773524183.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Cost: {cost}, Epoch: {epoch}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mimi_\\documents\\github\\gdelt_tgnn\\venv\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mimi_\\documents\\github\\gdelt_tgnn\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m def grad(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(10)):\n",
    "    cost = 0\n",
    "        \n",
    "    for time, snapshot in enumerate(dataset):\n",
    "        max_x = torch.nan_to_num(snapshot.x).max()\n",
    "        X = torch.div(snapshot.x, max_x + 1)\n",
    "\n",
    "        max_w = torch.nan_to_num(snapshot.edge_attr).max()\n",
    "        W = torch.div(snapshot.edge_attr, max_w + 1)\n",
    "\n",
    "        y_hat = model(X, snapshot.edge_index, W)\n",
    "\n",
    "        inner_cost = 0\n",
    "        for i, j in zip(snapshot.edge_index[0], snapshot.edge_index[1]):\n",
    "            pred = torch.dot(y_hat[i], y_hat[j])\n",
    "            if torch.isnan(pred):\n",
    "                pred = 0\n",
    "            true_val = snapshot.y[i][j]\n",
    "            if torch.isnan(true_val):\n",
    "                true_val = 0\n",
    "            exp = torch.pow(pred-true_val, 2)\n",
    "            inner_cost += exp\n",
    "        inner_cost /= (snapshot.edge_index.shape[0])\n",
    "        cost += inner_cost\n",
    "        \n",
    "    cost = cost / (time+1)\n",
    "    print(f'Cost: {cost}, Epoch: {epoch}')\n",
    "    cost.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 2, norm_type=2.0, error_if_nonfinite=False)\n",
    "                                   \n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.grad)\n",
    "        print(name, param.data)\n",
    "                                   \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
